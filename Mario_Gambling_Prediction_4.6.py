import asyncio
import aiohttp
from bs4 import BeautifulSoup
import pandas as pd
import streamlit as st
import math
import requests

# ---------------- Poisson æ¨¡å‹ ----------------
def poisson_pmf(k, lam):
    return math.exp(-lam) * (lam ** k) / math.factorial(k)

def predict_score(avg_home, avg_away, max_goals=10):
    dist = {(h,a): poisson_pmf(h, avg_home)*poisson_pmf(a, avg_away)
            for h in range(max_goals+1) for a in range(max_goals+1)}
    sorted_scores = sorted(dist.items(), key=lambda x: x[1], reverse=True)
    return sorted_scores[0][0], sorted_scores[0][0], dist

def prob_over_under(dist, line=2.5):
    over = sum(p for (h,a), p in dist.items() if h+a > line)
    under = sum(p for (h,a), p in dist.items() if h+a <= line)
    return over, under

def handicap_suggestion(home_goals, away_goals, handicap=0):
    diff = home_goals - away_goals
    if diff + handicap > 0:
        return "ä¸»éšŠå—è®“ âœ…"
    elif diff + handicap < 0:
        return "å®¢éšŠå—è®“ âœ…"
    else:
        return "å¹³æ‰‹/ä¸å»ºè­°ä¸‹æ³¨ âš ï¸"

# ---------------- è§’çƒé æ¸¬ ----------------
def predict_corner(avg_home_corner, avg_away_corner, max_corners=15):
    dist = {(h,a): poisson_pmf(h, avg_home_corner)*poisson_pmf(a, avg_away_corner)
            for h in range(max_corners+1) for a in range(max_corners+1)}
    sorted_scores = sorted(dist.items(), key=lambda x: x[1], reverse=True)
    return sorted_scores[0][0], sorted_scores[0][0], dist

def prob_corner_over_under(dist, line=9.5):
    over = sum(p for (h,a), p in dist.items() if h+a > line)
    under = sum(p for (h,a), p in dist.items() if h+a <= line)
    return over, under

# ---------------- Titan007 çˆ¬èŸ² ----------------
def fetch_titan007_matches(limit=50):
    url = "https://www.titan007.com/football/matchlist.htm"
    headers = {"User-Agent": "Mozilla/5.0"}
    resp = requests.get(url, headers=headers)
    data = []
    if resp.status_code == 200:
        soup = BeautifulSoup(resp.text, "html.parser")
        matches = soup.find_all("tr")
        for idx, m in enumerate(matches[1:limit+1]):
            cells = m.find_all("td")
            if len(cells) >= 4:
                data.append({
                    "æ¯”è³½ID": idx,
                    "æ—¥æœŸ": cells[0].text.strip(),
                    "è¯è³½": cells[1].text.strip(),
                    "ä¸»éšŠ": cells[2].text.strip(),
                    "å®¢éšŠ": cells[3].text.strip()
                })
    return pd.DataFrame(data)

def fetch_team_recent_matches(team_name, num_matches=5):
    url = f"https://www.titan007.com/football/team/{team_name}.htm"
    headers = {"User-Agent": "Mozilla/5.0"}
    resp = requests.get(url, headers=headers)
    goals = []
    if resp.status_code == 200:
        soup = BeautifulSoup(resp.text, "html.parser")
        matches = soup.find_all("tr")
        for m in matches[1:num_matches+1]:
            cells = m.find_all("td")
            if len(cells) >= 5:
                score_text = cells[4].text.strip()
                try:
                    h, a = map(int, score_text.split(":"))
                    if team_name in cells[2].text:
                        goals.append(h)
                    else:
                        goals.append(a)
                except:
                    continue
    return sum(goals)/len(goals) if goals else 1.0

def fetch_team_recent_corners(team_name, num_matches=5):
    url = f"https://www.titan007.com/football/team/{team_name}.htm"
    headers = {"User-Agent": "Mozilla/5.0"}
    resp = requests.get(url, headers=headers)
    corners = []
    if resp.status_code == 200:
        soup = BeautifulSoup(resp.text, "html.parser")
        matches = soup.find_all("tr")
        for m in matches[1:num_matches+1]:
            cells = m.find_all("td")
            if len(cells) >= 7:  # å‡è¨­è§’çƒåœ¨ç¬¬6ã€7åˆ—
                try:
                    h, a = map(int, cells[5].text.strip().split(":"))
                    corners.append((h, a))
                except:
                    continue
    avg_home_corner = sum(h for h,_ in corners)/len(corners) if corners else 4
    avg_away_corner = sum(a for _,a in corners)/len(corners) if corners else 4
    return avg_home_corner, avg_away_corner

def fetch_h2h(team_home, team_away, num_matches=5):
    url = f"https://www.titan007.com/football/h2h/{team_home}_vs_{team_away}.htm"
    headers = {"User-Agent": "Mozilla/5.0"}
    resp = requests.get(url, headers=headers)
    home_goals, away_goals = [], []
    if resp.status_code == 200:
        soup = BeautifulSoup(resp.text, "html.parser")
        matches = soup.find_all("tr")
        for m in matches[1:num_matches+1]:
            cells = m.find_all("td")
            if len(cells) >= 5:
                score_text = cells[4].text.strip()
                try:
                    h, a = map(int, score_text.split(":"))
                    home_goals.append(h)
                    away_goals.append(a)
                except:
                    continue
    avg_home = sum(home_goals)/len(home_goals) if home_goals else 1.0
    avg_away = sum(away_goals)/len(away_goals) if away_goals else 1.0
    return avg_home, avg_away

# ---------------- ç•°æ­¥æŠ“å– Titan007 å³æ™‚ç›¤ ----------------
async def fetch_odds_async(session, match_id):
    url = f"https://www.titan007.com/football/odds/{match_id}.htm"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        async with session.get(url, headers=headers) as resp:
            text = await resp.text()
            soup = BeautifulSoup(text, "html.parser")
            over_under = float(soup.select_one(".over-under").text or 2.5)
            ou_home = float(soup.select_one(".ou-home").text or 1)
            ou_away = float(soup.select_one(".ou-away").text or 1)
            handicap_home = float(soup.select_one(".handicap-home").text or 0)
            handicap_away = float(soup.select_one(".handicap-away").text or 0)
            return match_id, {"over_under": over_under, "ou_home": ou_home, "ou_away": ou_away,
                              "handicap_home": handicap_home, "handicap_away": handicap_away}
    except:
        return match_id, {"over_under":2.5,"ou_home":1,"ou_away":1,"handicap_home":0,"handicap_away":0}

async def fetch_all_odds(match_ids):
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_odds_async(session, mid) for mid in match_ids]
        results = await asyncio.gather(*tasks)
        return dict(results)

# ---------------- Streamlit ä»‹é¢ ----------------
st.set_page_config(page_title="Mario èµŒåšé¢„æµ‹ 4.6", layout="wide")
st.title("âš½ğŸ¯ Mario èµŒåšé¢„æµ‹ 4.6ï¼ˆå…¨ä¸­æ–‡ + Titan007 ç•°æ­¥å³æ™‚ç›¤ + è§’çƒé æ¸¬ï¼‰")

# 1ï¸âƒ£ æ¯”è³½åˆ—è¡¨
df_matches = fetch_titan007_matches()
st.subheader("ğŸ“Œ Titan007 æ¯”è³½åˆ—è¡¨")
st.dataframe(df_matches)

# 2ï¸âƒ£ è¯è³½é¸æ“‡
leagues = df_matches['è¯è³½'].unique().tolist()
selected_league = st.selectbox("é¸æ“‡è¯è³½", leagues)
league_matches = df_matches[df_matches['è¯è³½']==selected_league]

# 3ï¸âƒ£ æ‰¹é‡æ¯”åˆ†èˆ‡è§’çƒé æ¸¬
if not league_matches.empty:
    st.subheader("ğŸ“Š æ¯”è³½é æ¸¬ï¼ˆå¤šå ´ï¼‰")
    predictions = []

    # ç•°æ­¥æŠ“å–å³æ™‚ç›¤
    match_ids = league_matches['æ¯”è³½ID'].tolist()
    odds_data = asyncio.run(fetch_all_odds(match_ids))

    for idx, row in league_matches.iterrows():
        recent_home = fetch_team_recent_matches(row['ä¸»éšŠ'])
        recent_away = fetch_team_recent_matches(row['å®¢éšŠ'])
        avg_home_corner, avg_away_corner = fetch_team_recent_corners(row['ä¸»éšŠ']), fetch_team_recent_corners(row['å®¢éšŠ'])
        h2h_home, h2h_away = fetch_h2h(row['ä¸»éšŠ'], row['å®¢éšŠ'])
        avg_home = (recent_home + h2h_home)/2
        avg_away = (recent_away + h2h_away)/2

        # æ¯”åˆ†
        pred_home, pred_away, dist = predict_score(avg_home, avg_away)
        over_prob, under_prob = prob_over_under(dist)

        # è§’çƒ
        corner_pred_home, corner_pred_away, corner_dist = predict_corner(avg_home_corner, avg_away_corner)
        corner_over_prob, corner_under_prob = prob_corner_over_under(corner_dist)

        odds = odds_data.get(row['æ¯”è³½ID'], {})
        advice = handicap_suggestion(pred_home, pred_away, handicap=0)

        # Emoji æ¨™è¨˜
        score_emoji = "âš¡"
        over_emoji = "ğŸ“ˆ" if over_prob > 0.6 else ""
        under_emoji = "ğŸ“‰" if under_prob > 0.6 else ""
        corner_over_emoji = "ğŸ“ˆ" if corner_over_prob > 0.6 else ""
        corner_under_emoji = "ğŸ“‰" if corner_under_prob > 0.6 else ""
        advice_emoji = "ğŸ†" if "âœ…" in advice else ""

        predictions.append({
            "æ—¥æœŸ": row['æ—¥æœŸ'],
            "ä¸»éšŠ": row['ä¸»éšŠ'],
            "å®¢éšŠ": row['å®¢éšŠ'],
            "é æ¸¬æ¯”åˆ†": f"{pred_home}-{pred_away} {score_emoji}",
            "å¤§æ–¼ 2.5 æ©Ÿç‡": f"{over_prob:.1%} {over_emoji}",
            "å°æ–¼ 2.5 æ©Ÿç‡": f"{under_prob:.1%} {under_emoji}",
            "è®“çƒç›¤å»ºè­°": f"{advice} {advice_emoji}",
            "å¤§å°çƒå³æ™‚ç›¤": f"{odds.get('ou_home', '-')}/{odds.get('ou_away', '-')}",
            "è®“çƒç›¤å³æ™‚ç›¤": f"{odds.get('handicap_home', '-')}/{odds.get('handicap_away', '-')}",
            "é æ¸¬è§’çƒæ¯”åˆ†": f"{corner_pred_home}-{corner_pred_away}",
            "è§’çƒå¤§æ–¼ 9.5 æ©Ÿç‡": f"{corner_over_prob:.1%} {corner_over_emoji}",
            "è§’çƒå°æ–¼ 9.5 æ©Ÿç‡": f"{corner_under_prob:.1%} {corner_under_emoji}"
        })

    df_pred = pd.DataFrame(predictions)
    st.dataframe(df_pred)